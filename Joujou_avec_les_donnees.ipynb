{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données\n",
    "\n",
    "Afin de bien exploiter nos donner, on va devoir les préparer :\n",
    "\n",
    "- Lire les données\n",
    "- Combien d'élements elles contiennent ? Combien de classes différentes ?\n",
    "- Comment diviser nos deonnées en données d'entrainement, de validation et de test ?\n",
    "\n",
    "Répondons à ces questions une par une :\n",
    "\n",
    "## Lecture des données\n",
    "\n",
    "Les données sont enregistré dans le format csv, les 93 premières colonnes représentent les attributs d'un individu x et la dernière colonne représente sa classe.\n",
    "\n",
    "A partir de là il est facile d'extraire la population et les calsses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 30 days\n"
     ]
    }
   ],
   "source": [
    "# Preparing training data\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "trainData = []\n",
    "with open('Data/train.csv', 'rb') as trainFile:\n",
    "    reader = csv.reader(trainFile)\n",
    "    i = 0\n",
    "    reader.next()\n",
    "    for r in reader:\n",
    "        trainData.append((r[1:len(r) - 1],r[len(r) - 1]))\n",
    "\n",
    "np.random.shuffle(trainData)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combien d'élements elles contiennent ? Combien de classes différentes ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La population à une taille de  61878 individus\n",
      "Le nombre de classes auquelles peut appartenir un individu est de  9\n"
     ]
    }
   ],
   "source": [
    "classes = np.array([c for _,c in trainData])\n",
    "\n",
    "# Les élément sont enregistrés comme string afin de les manipuler on doit les convertir en float\n",
    "featuresString = np.array([f for f,_ in trainData])\n",
    "features = np.array([x.astype(np.float) for x in featuresString])\n",
    "\n",
    "print \"La population à une taille de \", len(features) , \"individus\"\n",
    "print \"Le nombre de classes auquelles peut appartenir un individu est de \" , len(set(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de nous aider pour la suite, nous allons définir une fonction qui retourne un identifiant unique pour chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnIndex(classe):\n",
    "    return (int(classe[len(classe )- 1]) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combien d'individus contient chaque classes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre d'individus de la classe  1 est de :  1929.0\n",
      "Le nombre d'individus de la classe  2 est de :  16122.0\n",
      "Le nombre d'individus de la classe  3 est de :  8004.0\n",
      "Le nombre d'individus de la classe  4 est de :  2691.0\n",
      "Le nombre d'individus de la classe  5 est de :  2739.0\n",
      "Le nombre d'individus de la classe  6 est de :  14135.0\n",
      "Le nombre d'individus de la classe  7 est de :  2839.0\n",
      "Le nombre d'individus de la classe  8 est de :  8464.0\n",
      "Le nombre d'individus de la classe  9 est de :  4955.0\n"
     ]
    }
   ],
   "source": [
    "nums = np.zeros(len(set(classes)))\n",
    "for i in range(len(features)):\n",
    "    inx = returnIndex(classes[i])\n",
    "    nums[inx] +=1\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(len(set(classes))):\n",
    "    print \"Le nombre d'individus de la classe \", i+1 ,\"est de : \", nums[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Division des données en 10 Paquets avec uen distribution de classes similaire à l'original\n",
    "\n",
    "### Récupération des élément de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/notebook/src/ipykernel/ipykernel/__main__.py:16: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_packed = {}\n",
    "\n",
    "for i in range(len(set(classes))):    \n",
    "    features_packed[i] = features[np.where([c == i  for c in [ returnIndex(t) for t in classes]] ) ]  \n",
    "\n",
    "\n",
    "diveded_features = {}\n",
    "\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "    diveded_features[j] = []\n",
    "    for i in range(len(set(classes))):\n",
    "        ind = np.floor(nums[i]/10)\n",
    "        x = features_packed[i][j*ind:j*ind+ind]\n",
    "        diveded_features[j].append(x)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for k in diveded_features:\n",
    "    with open(\"Data/otto%i.csv\" %k,\"wb\") as fout :\n",
    "        out = csv.writer(fout)\n",
    "        for i in range(len(diveded_features[k])):\n",
    "            for x in diveded_features[k][i]:\n",
    "                f = np.append(x,i)\n",
    "                out.writerows([f])\n",
    "\n",
    "print sum([len(diveded_features[8][i]) for i in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sepIndex = len(features)*10/100\n",
    "trainFeatures = features[:len(features) - sepIndex*2]\n",
    "devFeatures = features[len(features) - sepIndex*2 + 1 : len(features) - sepIndex]\n",
    "print len(devFeatures)\n",
    "\n",
    "\n",
    "\n",
    "numtrainData = len(features)\n",
    "numClasses = len(set(classes))\n",
    "\n",
    "nums = np.zeros(numClasses)\n",
    "\n",
    "u = np.zeros((numClasses,features.shape[1]),float)\n",
    "var = np.zeros((numClasses,features.shape[1]),float)\n",
    "\n",
    "for i in range(numtrainData):\n",
    "    inx = returnIndex(classes[i])\n",
    "    nums[inx] +=1\n",
    "    u[inx] += features[i]\n",
    "    \n",
    "u = u/nums[:,np.newaxis]   \n",
    "\n",
    "for i in range(numtrainData):\n",
    "    inx = returnIndex(classes[i])\n",
    "    var[inx] += (features[i] - u[inx])**2\n",
    "    \n",
    "var = var / nums[:,np.newaxis]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    \n",
    "    p = np.zeros((numClasses),float)\n",
    "    \n",
    "    for i in range(len(p)):\n",
    "        p[i] = (1.0/np.sqrt(2*np.pi*(np.linalg.norm(var[i]))))*np.exp(-(np.linalg.norm((x-u[i])**2))/(2*np.linalg.norm(var[i])))\n",
    "    \n",
    "    r = np.argmax(p)\n",
    "    \n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590306732603\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "\n",
    "for i in range(len(features)):\n",
    "    r = predict(features[i])\n",
    "    if(r != returnIndex(classes[i])):\n",
    "        errors += 1\n",
    "        \n",
    "print float(errors)/features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Class_8\n"
     ]
    }
   ],
   "source": [
    "print predict(features[1000])\n",
    "print classes[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 61878 points : 23699\n",
      "0.382995571932\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(features, classes).predict(features)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (features.shape[0],(classes != y_pred).sum()))\n",
    "print float((classes != y_pred).sum())/features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
